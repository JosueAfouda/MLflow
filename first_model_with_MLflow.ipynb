{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "first-model-with-MLflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOwD9adYh3IZqjRwnWBs4Z2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JosueAfouda/MLflow/blob/main/first_model_with_MLflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eLRPbrSmRSb",
        "outputId": "645aa2e1-ff3c-4579-fdcf-653c4bf63207"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mlflow\n",
            "  Downloading mlflow-1.27.0-py3-none-any.whl (17.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.9 MB 471 kB/s \n",
            "\u001b[?25hCollecting prometheus-flask-exporter\n",
            "  Downloading prometheus_flask_exporter-0.20.3-py3-none-any.whl (18 kB)\n",
            "Collecting docker>=4.0.0\n",
            "  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 56.3 MB/s \n",
            "\u001b[?25hCollecting alembic\n",
            "  Downloading alembic-1.8.1-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 53.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.4.39)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.21.6)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from mlflow) (0.4)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 50.8 MB/s \n",
            "\u001b[?25hCollecting querystring-parser\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (7.1.2)\n",
            "Collecting databricks-cli>=0.8.7\n",
            "  Downloading databricks-cli-0.17.0.tar.gz (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.3.5)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from mlflow) (2022.1)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (3.17.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mlflow) (21.3)\n",
            "Requirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from mlflow) (0.4.2)\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.1.4)\n",
            "Collecting gitpython>=2.1.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 37.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.17.3 in /usr/local/lib/python3.7/dist-packages (from mlflow) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (4.12.0)\n",
            "Collecting gunicorn\n",
            "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 6.6 MB/s \n",
            "\u001b[?25hCollecting pyjwt>=1.7.0\n",
            "  Downloading PyJWT-2.4.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow) (3.2.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow) (0.8.10)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow) (1.15.0)\n",
            "Collecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-1.3.3-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.7 MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from gitpython>=2.1.0->mlflow) (4.1.1)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata!=4.7.0,>=3.7.0->mlflow) (3.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (1.24.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.4.0->mlflow) (1.1.2)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->mlflow) (5.9.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.1-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 7.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask->mlflow) (2.0.1)\n",
            "Requirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.7/dist-packages (from gunicorn->mlflow) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mlflow) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->mlflow) (2.8.2)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from prometheus-flask-exporter->mlflow) (0.14.1)\n",
            "Building wheels for collected packages: databricks-cli\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.17.0-py3-none-any.whl size=141960 sha256=6c31a7f91ea6d8db1dd0c9859e54c968a9a99f0e9ecdd87dc7f02e364de8b677\n",
            "  Stored in directory: /root/.cache/pip/wheels/55/c3/db/33705569425fd2bdc9ea73051a8053fa26965c2bce8a146747\n",
            "Successfully built databricks-cli\n",
            "Installing collected packages: smmap, websocket-client, pyjwt, Mako, gitdb, querystring-parser, pyyaml, prometheus-flask-exporter, gunicorn, gitpython, docker, databricks-cli, alembic, mlflow\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed Mako-1.2.1 alembic-1.8.1 databricks-cli-0.17.0 docker-5.0.3 gitdb-4.0.9 gitpython-3.1.27 gunicorn-20.1.0 mlflow-1.27.0 prometheus-flask-exporter-0.20.3 pyjwt-2.4.0 pyyaml-6.0 querystring-parser-1.2.4 smmap-5.0.0 websocket-client-1.3.3\n"
          ]
        }
      ],
      "source": [
        "#pip install mlflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "dataset = datasets.load_iris()\n",
        "seed = 123\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    dataset.data,\n",
        "    dataset.target,\n",
        "    test_size = 0.4,\n",
        "    random_state = seed\n",
        ")\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gO2Wg2O2mhgd",
        "outputId": "23200eea-cc04-4b75-ce19-203145a9c33c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(90, 4)\n",
            "(90,)\n",
            "(60, 4)\n",
            "(60,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0W5P6OEZsiYo",
        "outputId": "8a619fda-eb51-4ce4-fc16-92b71bdf9e4c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.5, 2.3, 1.3, 0.3],\n",
              "       [6.7, 3.3, 5.7, 2.1],\n",
              "       [5.7, 3. , 4.2, 1.2],\n",
              "       [5.1, 3.7, 1.5, 0.4],\n",
              "       [4.8, 3.4, 1.6, 0.2],\n",
              "       [6.3, 2.9, 5.6, 1.8],\n",
              "       [6.4, 2.9, 4.3, 1.3],\n",
              "       [7.7, 2.8, 6.7, 2. ],\n",
              "       [7.7, 2.6, 6.9, 2.3],\n",
              "       [5.1, 3.8, 1.9, 0.4],\n",
              "       [6.4, 3.2, 4.5, 1.5],\n",
              "       [5.5, 2.4, 3.7, 1. ],\n",
              "       [5.9, 3. , 5.1, 1.8],\n",
              "       [4.8, 3. , 1.4, 0.1],\n",
              "       [7.2, 3. , 5.8, 1.6],\n",
              "       [6.3, 3.3, 4.7, 1.6],\n",
              "       [7. , 3.2, 4.7, 1.4],\n",
              "       [5. , 3. , 1.6, 0.2],\n",
              "       [6.4, 2.8, 5.6, 2.1],\n",
              "       [6.3, 2.5, 5. , 1.9],\n",
              "       [5. , 3.5, 1.6, 0.6],\n",
              "       [4.9, 3. , 1.4, 0.2],\n",
              "       [6.1, 2.8, 4. , 1.3],\n",
              "       [6.5, 2.8, 4.6, 1.5],\n",
              "       [6.3, 3.3, 6. , 2.5],\n",
              "       [5.8, 4. , 1.2, 0.2],\n",
              "       [4.6, 3.4, 1.4, 0.3],\n",
              "       [5.5, 2.4, 3.8, 1.1],\n",
              "       [5. , 3.4, 1.6, 0.4],\n",
              "       [5.9, 3.2, 4.8, 1.8],\n",
              "       [6.9, 3.1, 5.4, 2.1],\n",
              "       [4.8, 3.1, 1.6, 0.2],\n",
              "       [6.7, 2.5, 5.8, 1.8],\n",
              "       [5.7, 4.4, 1.5, 0.4],\n",
              "       [5.7, 3.8, 1.7, 0.3],\n",
              "       [6.7, 3. , 5. , 1.7],\n",
              "       [4.6, 3.6, 1. , 0.2],\n",
              "       [5.4, 3.7, 1.5, 0.2],\n",
              "       [6.6, 2.9, 4.6, 1.3],\n",
              "       [7.3, 2.9, 6.3, 1.8],\n",
              "       [6.6, 3. , 4.4, 1.4],\n",
              "       [5.6, 2.9, 3.6, 1.3],\n",
              "       [5.6, 2.5, 3.9, 1.1],\n",
              "       [4.6, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.5, 1.3, 0.3],\n",
              "       [6.8, 2.8, 4.8, 1.4],\n",
              "       [6.1, 2.6, 5.6, 1.4],\n",
              "       [4.9, 3.1, 1.5, 0.2],\n",
              "       [5.2, 3.5, 1.5, 0.2],\n",
              "       [5.6, 2.7, 4.2, 1.3],\n",
              "       [6. , 3.4, 4.5, 1.6],\n",
              "       [6.2, 2.9, 4.3, 1.3],\n",
              "       [7.1, 3. , 5.9, 2.1],\n",
              "       [6.9, 3.1, 4.9, 1.5],\n",
              "       [5.8, 2.6, 4. , 1.2],\n",
              "       [5.7, 2.8, 4.1, 1.3],\n",
              "       [7.6, 3. , 6.6, 2.1],\n",
              "       [5. , 3.4, 1.5, 0.2],\n",
              "       [5.3, 3.7, 1.5, 0.2],\n",
              "       [5.9, 3. , 4.2, 1.5],\n",
              "       [6.9, 3.2, 5.7, 2.3],\n",
              "       [6.4, 3.1, 5.5, 1.8],\n",
              "       [7.2, 3.2, 6. , 1.8],\n",
              "       [6.5, 3. , 5.2, 2. ],\n",
              "       [5.1, 3.4, 1.5, 0.2],\n",
              "       [5.4, 3. , 4.5, 1.5],\n",
              "       [4.7, 3.2, 1.3, 0.2],\n",
              "       [5.8, 2.7, 4.1, 1. ],\n",
              "       [5.7, 2.8, 4.5, 1.3],\n",
              "       [5. , 3.3, 1.4, 0.2],\n",
              "       [6.2, 2.2, 4.5, 1.5],\n",
              "       [6.7, 3.1, 5.6, 2.4],\n",
              "       [6. , 2.9, 4.5, 1.5],\n",
              "       [6.7, 3.3, 5.7, 2.5],\n",
              "       [6.4, 2.7, 5.3, 1.9],\n",
              "       [5.2, 4.1, 1.5, 0.1],\n",
              "       [6.1, 2.8, 4.7, 1.2],\n",
              "       [4.6, 3.2, 1.4, 0.2],\n",
              "       [6.2, 3.4, 5.4, 2.3],\n",
              "       [5.7, 2.5, 5. , 2. ],\n",
              "       [5.7, 2.9, 4.2, 1.3],\n",
              "       [4.9, 2.4, 3.3, 1. ],\n",
              "       [6.3, 2.7, 4.9, 1.8],\n",
              "       [4.9, 2.5, 4.5, 1.7],\n",
              "       [6. , 2.7, 5.1, 1.6],\n",
              "       [5.1, 3.5, 1.4, 0.3],\n",
              "       [5.1, 2.5, 3. , 1.1],\n",
              "       [5.6, 3. , 4.5, 1.5],\n",
              "       [6.2, 2.8, 4.8, 1.8],\n",
              "       [7.2, 3.6, 6.1, 2.5]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXW_BdiHt7NO",
        "outputId": "38a1fa93-fb66-4a6f-a49a-e0916eef5214"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 1, 0, 0, 2, 1, 2, 2, 0, 1, 1, 2, 0, 2, 1, 1, 0, 2, 2, 0, 0,\n",
              "       1, 1, 2, 0, 0, 1, 0, 1, 2, 0, 2, 0, 0, 1, 0, 0, 1, 2, 1, 1, 1, 0,\n",
              "       0, 1, 2, 0, 0, 1, 1, 1, 2, 1, 1, 1, 2, 0, 0, 1, 2, 2, 2, 2, 0, 1,\n",
              "       0, 1, 1, 0, 1, 2, 1, 2, 2, 0, 1, 0, 2, 2, 1, 1, 2, 2, 1, 0, 1, 1,\n",
              "       2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "clf = LogisticRegression()\n",
        "clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mit3OyavnoVP",
        "outputId": "61cd1692-3233-479b-9dfb-1e673231ab1b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En ajoutant quelques lignes de code au script précédent, on peut déjà enregistrer une première expérience avec MLflow."
      ],
      "metadata": {
        "id": "74FjrLYPoDC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "import mlflow\n",
        "# Définition d'une expérience (Une expérience peut contenir plusieurs *runs*)\n",
        "mlflow.set_experiment(\"Reg_Logistic_Models\")\n",
        "mlflow.sklearn.autolog() # Ici on fait appel à l'API MLflow qui intégre les algos de Scikit-Learn.\n",
        "                        # C'est grâce à ce code qu'on enregistre toutes les métriques et métadonnées de cette expérience (Module MLflow Tracking)\n",
        "with mlflow.start_run(run_name = 'reg_logistic_defaut'):\n",
        "  clf = LogisticRegression()\n",
        "  clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_T7r_rghoRNo",
        "outputId": "b4a4f819-a237-4372-8c34-d59a0f337349"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022/08/05 15:37:45 INFO mlflow.tracking.fluent: Experiment with name 'Reg_Logistic_Models' does not exist. Creating a new experiment.\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Création d'un second run dans la même expérience\n",
        "with mlflow.start_run(run_name = 'reg_logistic_max_iter_200'):\n",
        "  clf2 = LogisticRegression(max_iter=200)\n",
        "  clf2.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Hwun_pZRqBEG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Création d'une seconde expérience\n",
        "mlflow.set_experiment(\"Decision_Tree_Models\")\n",
        "mlflow.sklearn.autolog()\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "with mlflow.start_run(run_name = 'decision_tree_defaut'):\n",
        "  dt1 = DecisionTreeClassifier(random_state=seed)\n",
        "  dt1.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTW78NxFtcRa",
        "outputId": "dace2b33-f34c-44d6-c657-7e05f7b5062a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022/08/05 16:00:04 INFO mlflow.tracking.fluent: Experiment with name 'Decision_Tree_Models' does not exist. Creating a new experiment.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with mlflow.start_run(run_name = 'decision_tree_max_depth3'):\n",
        "  dt2 = DecisionTreeClassifier(random_state=seed, max_depth=3)\n",
        "  dt2.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "dbwEeoSivEuI"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "new_data = np.array([[6.5, 3.2, 5.5, 1.9]])\n",
        "new_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpScaN99sxbI",
        "outputId": "248a70a8-47f5-4d3c-e09b-cc666770b904"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.5, 3.2, 5.5, 1.9]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QaYkKpttQSR",
        "outputId": "7c4afad6-a7e7-49fb-dc45-5d6d84b65da0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prédictions\n",
        "logged_model = 'runs:/12366ea03957424891b6f90e65086664/model'\n",
        "\n",
        "# Load model as a PyFuncModel.\n",
        "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
        "\n",
        "# Predict on a Pandas DataFrame.\n",
        "import pandas as pd\n",
        "prediction = loaded_model.predict(new_data)\n",
        "prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQU_iEXRsfC5",
        "outputId": "e858dd04-eaac-4801-89fb-ef571eed692e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZ0ADKmaqZ_-",
        "outputId": "33e332af-d876-45d6-b1dd-d455da3aa12a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-5.1.0.tar.gz (745 kB)\n",
            "\u001b[K     |████████████████████████████████| 745 kB 7.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok) (6.0)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-5.1.0-py3-none-any.whl size=19007 sha256=b95ed2f31c52a6a3268ddb2fc515c356dd4f39da6423a121e44ed4f8718d93e0\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/e6/af/ccf6598ecefecd44104069371795cb9b3afbcd16987f6ccfb3\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-5.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "# Terminate open tunnels if exist\n",
        "ngrok.kill()\n",
        "\n",
        "# Setting the authtoken (optional)\n",
        "# Get your authtoken from https://dashboard.ngrok.com/auth\n",
        "NGROK_AUTH_TOKEN = \"\" \n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "# Open an HTTPs tunnel on port 5000 for http://localhost:5000\n",
        "ngrok_tunnel = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)\n",
        "print(\"MLflow Tracking UI:\", ngrok_tunnel.public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcb_MMDwmrfR",
        "outputId": "1e7ee843-b270-4ed4-82fd-01e40b5205f3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLflow Tracking UI: https://1d60-34-82-250-245.ngrok.io\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mlflow ui"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5FS-s6_ms78",
        "outputId": "03163e2b-6b0e-48fc-bbdb-4767207f18ca"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2022-08-05 16:02:30 +0000] [699] [INFO] Starting gunicorn 20.1.0\n",
            "[2022-08-05 16:02:30 +0000] [699] [INFO] Listening at: http://127.0.0.1:5000 (699)\n",
            "[2022-08-05 16:02:30 +0000] [699] [INFO] Using worker: sync\n",
            "[2022-08-05 16:02:30 +0000] [702] [INFO] Booting worker with pid: 702\n",
            "[2022-08-05 16:31:48 +0000] [699] [INFO] Handling signal: int\n",
            "[2022-08-05 16:31:48 +0000] [702] [INFO] Worker exiting (pid: 702)\n",
            "\n",
            "Aborted!\n",
            "[2022-08-05 16:31:49 +0000] [699] [INFO] Shutting down: Master\n"
          ]
        }
      ]
    }
  ]
}